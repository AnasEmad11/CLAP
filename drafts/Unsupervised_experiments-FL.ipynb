{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '1'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# probability model\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(\"C:/Users/User/PycharmProjects/FL_AD/concat_UCF_V2.npy\") #UCF\n",
    "# train_data = np.load(\"/home/anas.al-lahham/AD_Unsupervised/concat_XD_I3D.npy\") #XD\n",
    "train_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1 = train_data[171:]\n",
    "train_data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"concat_UCF_V2.npy\", train_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[:,0,0:1024]\n",
    "# train_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nalist = np.load(\"C:/Users/User/PycharmProjects/FL_AD/nalist.npy\") #UCF\n",
    "nalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_gauss(X):\n",
    "    m = X.shape[0]   # using only first dimension as we know it has only one feature - l2 norm\n",
    "    \n",
    "    mu = np.mean(X, axis=0)\n",
    "    var = np.cov(X.T)\n",
    "    \n",
    "    return mu, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_gauss(X):\n",
    "    m = X.shape[0]   # using only first dimension as we know it has only one feature - l2 norm\n",
    "    \n",
    "    mu = 1 / m * np.sum(X, axis=0)\n",
    "    var = 1 / m * np.sum((X - mu) ** 2, axis=0)\n",
    "    \n",
    "    return mu, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_repr = []\n",
    "for i, (fromid, toid) in enumerate(nalist):\n",
    "    new_repr.append(train_data[fromid:toid])\n",
    "\n",
    "len(new_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_repr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix(data):\n",
    "    # 1st: L2 norm [Euclidean Distance]\n",
    "    # l2_norm = np.sum(np.square(data), axis=2)\n",
    "    l2_norm = np.sum(np.square(data), axis=2)\n",
    "    n_train_crop_l2_norm_mean = np.mean(l2_norm, axis= 1)\n",
    "    # print(n_train_crop_l2_norm_mean.shape)\n",
    "    \n",
    "    # n_train_crop_l2_norm_mean_normal = Transform_normal(n_train_crop_l2_norm_mean)\n",
    "    return n_train_crop_l2_norm_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "for i in range(len(new_repr)):\n",
    "    # l2_norm = np.sum(np.square(new_repr[i]), axis=2)\n",
    "    # mean_l2 =  np.mean(l2_norm, axis= 1)\n",
    "    param = get_matrix(new_repr[i])\n",
    "    mu, var = estimate_gauss(param)\n",
    "    # print( mu, var )\n",
    "    # l2mean = np.sum(np.square(new_repr[i]), a\n",
    "    # xis=1).mean()\n",
    "    # mmean = np.mean(new_repr[i], axis=0)\n",
    "    params.append((mu, var, ))\n",
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.load(\"C:/Users/User/PycharmProjects/FL_AD/params_UCF.npy\")\n",
    "params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(sklearn.show_versions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "# import time\n",
    "\n",
    "\n",
    "gmm = GaussianMixture(n_components=2, max_iter=50, random_state=0, covariance_type='spherical')\n",
    "# gmm_scores = gmm.score_samples(params)\n",
    "labels = gmm.fit_predict(params)\n",
    "\n",
    "# y_gmm = gmm.fit_predict(params)\n",
    "# print(y_gmm.sum(), y_gmm.sum() / len(y_gmm))\n",
    "\n",
    "# score = y_gmm \n",
    "# score = gmm.score_samples(params) \n",
    "# pct_threshold = np.percentile(score, 3)\n",
    "# print(f'The threshold of the score is {pct_threshold:.2f}') \n",
    "# res = np.array([1 if x < pct_threshold else 0 for x in score]) \n",
    "# print(res.sum())\n",
    "np.where(labels== 1)[0].shape, np.where(labels == 0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, MeanShift, DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KM = KMeans(n_clusters=2, random_state=0, n_init=\"auto\").fit(params[:200])\n",
    "KM.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=150, min_samples=5 )\n",
    "db.fit_predict(params[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.labels_\n",
    "np.where(db.labels_ == -1)[0].shape, np.where(db.labels_ == 0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(db.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmm = GaussianMixture(n_components=2, max_iter=500,covariance_type= 'spherical', tol=1e-9).fit(params)\n",
    "gmm_scores = gmm.score_samples(params)\n",
    "labels = gmm.predict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_portion = np.where(res == 1)[0]\n",
    "normal_portion = np.where(res == 0)[0]\n",
    "normal_portion.shape, abnormal_portion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params = np.array(params)[normal_portion]\n",
    "a_params = np.array(params)[abnormal_portion]\n",
    "n_params.shape, a_params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "gmm1 = GaussianMixture(n_components=2, max_iter=100,covariance_type= 'spherical', tol=1e-9)\n",
    "# gmm_scores = gmm1.score_samples(n_params)\n",
    "labels1 = gmm1.fit_predict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(labels1 ==0)[0].shape, np.where(labels1 ==1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_labels_1 = labels\n",
    "video_labels_2 = labels1\n",
    "video_labels_1.shape, video_labels_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_labels_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.full(video_labels_1.shape[0] - video_labels_2.shape[0] ,1)\n",
    "video_labels_2 = np.concatenate((video_labels_2, a))\n",
    "video_labels_1.shape, video_labels_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_portion = np.where(video_labels_2 == 0)[0]\n",
    "normal_portion = np.where(video_labels_2 == 1)[0]\n",
    "abnormal_portion.shape, normal_portion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_portion = np.where(video_labels_2 == 1)[0]\n",
    "normal_portion = np.where(video_labels_2 == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abag = list(zip(list(np.array(params)[abnormal_portion]), abnormal_portion))\n",
    "nbag = list(zip(list(np.array(params)[normal_portion]), normal_portion))\n",
    "len(abag), len(nbag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = 1.0\n",
    "step = 1\n",
    "import time\n",
    "start = time.time()\n",
    "while len(abag) / len(nbag) < nu:\n",
    "    \n",
    "    temp_bag = nbag\n",
    "    y_gmm = gmm.fit_predict([list(x[0]) for x in np.array(temp_bag)])\n",
    "    score = y_gmm \n",
    "    score = gmm.score_samples([list(x[0]) for x in np.array(temp_bag)]) \n",
    "    pct_threshold = np.percentile(score, 3) \n",
    "    res = np.array([1 if x < pct_threshold else 0 for x in score]) \n",
    "    print(f'The threshold of the score in step {step} is {pct_threshold:.2f}, abnormal part: {res.sum()}') \n",
    "    \n",
    "    abnormal_portion = np.where(res == 1)[0]\n",
    "    normal_portion = np.where(res == 0)[0]\n",
    "    \n",
    "    abag += [(x[0], x[1]) for x in np.array(temp_bag)[abnormal_portion]]\n",
    "    nbag = [(x[0], x[1]) for x in np.array(temp_bag)[normal_portion]]\n",
    "\n",
    "    step += 1\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "abnormal_portion = np.where(res == 1)[0]\n",
    "normal_portion = np.where(res == 0)[0]\n",
    "abag = list(zip(list(np.array(params)[abnormal_portion]), abnormal_portion))\n",
    "nbag = list(zip(list(np.array(params)[normal_portion]), normal_portion))\n",
    "len(abag), len(nbag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "while len(abag) / len(nbag) < nu:\n",
    "    \n",
    "    temp_bag = nbag\n",
    "    y_gmm = gmm.fit_predict([list(x[0]) for x in np.array(temp_bag)])\n",
    "    score = y_gmm \n",
    "    score = gmm.score_samples([list(x[0]) for x in np.array(temp_bag)]) \n",
    "    pct_threshold = np.percentile(score, 1.) \n",
    "    res = np.array([1 if x < pct_threshold else 0 for x in score]) \n",
    "    print(f'The threshold of the score in step {step} is {pct_threshold:.2f}, abnormal part: {res.sum()}') \n",
    "    \n",
    "    abnormal_portion = np.where(res == 1)[0]\n",
    "    normal_portion = np.where(res == 0)[0]\n",
    "    \n",
    "    abag += [(x[0], x[1]) for x in np.array(temp_bag)[abnormal_portion]]\n",
    "    nbag = [(x[0], x[1]) for x in np.array(temp_bag)[normal_portion]]\n",
    "\n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(abag), len(nbag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(np.array([x[1] for x in abag]) < 810)[0].shape, len([x[1] for x in abag]))\n",
    "print('correctness acc: ', np.where(np.array([x[1] for x in abag]) < 810)[0].shape[0] / len([x[1] for x in abag]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(np.array([x[1] for x in nbag]) > 810)[0].shape, len([x[1] for x in nbag]))\n",
    "print('correctness acc: ', np.where(np.array([x[1] for x in nbag]) > 810)[0].shape[0] / len([x[1] for x in nbag]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(res ==0)[0].shape, np.where(res ==1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_labels_1 = labels\n",
    "video_labels_2 = labels1\n",
    "video_labels_1.shape, video_labels_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.full(video_labels_1.shape[0] - video_labels_2.shape[0] ,1)\n",
    "video_labels_2 = np.concatenate((video_labels_2, a))\n",
    "video_labels_1.shape, video_labels_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [k[1] for k in sorted([(x[1], 1.0) for x in abag] + [(x[1], 0.0) for x in nbag], key=lambda z: z[0])]\n",
    "sum(temp), len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal set creation\n",
    "normal_set = {}\n",
    "\n",
    "for i in range(len(new_repr)):\n",
    "    if video_labels_2[i] == 0.0:\n",
    "        normal_set[i] = new_repr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abnormal set creation\n",
    "abnormal_set = {}\n",
    "for i in range(len(new_repr)):\n",
    "    if video_labels_2[i] == 1.0:\n",
    "        abnormal_set[i] = new_repr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_norms_N = np.empty(0,)\n",
    "for (idel, sample) in normal_set.items():\n",
    "    \n",
    "    # print(sample.shape)\n",
    "    \n",
    "\n",
    "    l2_norms_N = np.append(l2_norms_N,get_matrix(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(normal_set), len(abnormal_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_GMM, var_GMM = estimate_gauss(np.array(l2_norms_N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability model\n",
    "from scipy.stats import multivariate_normal\n",
    "p = multivariate_normal(mu_GMM, var_GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = {} \n",
    "length = 0.2 \n",
    "for (idel, sample) in abnormal_set.items(): \n",
    "\n",
    "    # feature extraction \n",
    "    # sample_matrix = np.sum(np.square(sample), axis=1)  # for just l2\n",
    "    sample_matrix = get_matrix(sample)\n",
    "    \n",
    "    # get p values\n",
    "    probs = p.pdf(sample_matrix)\n",
    "    temp_list = []\n",
    "    temp_list += [0.0] * len(probs)\n",
    "    \n",
    "    window_size = int(len(probs) * length)  # fixed\n",
    "    temp = []\n",
    "    for idx in range(0, len(probs) - window_size + 1):\n",
    "        arr = 0\n",
    "        for i in range(idx, idx + window_size - 1):\n",
    "            arr += abs(probs[i+1] - probs[i])\n",
    "        temp.append(arr)\n",
    "\n",
    "    for i in range(temp.index(max(temp)), temp.index(max(temp)) + window_size):\n",
    "        temp_list[i] = 1.0\n",
    "\n",
    "    ground_truth[idel] = temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_gt = []\n",
    "abnormal_gt = []\n",
    "for i in range(len(new_repr)):\n",
    "    if i in normal_set.keys():\n",
    "        final_gt += [0.0] * new_repr[i].shape[0]\n",
    "    else:\n",
    "        final_gt += ground_truth[i]\n",
    "        abnormal_gt+= ground_truth[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('unsupervised_PL/'+'UCF_labels_V2_w_20.npy', final_gt) #UCF\n",
    "# np.save('Unsup_labels/'+'XD_I3D_unsup_labels_10_V2_GMM.npy', final_gt) #XD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Video-level labels experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 1609 random weak labels either 0 or 1\n",
    "rand_temp = np.random.randint(2, size=1609)\n",
    "rand_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal set creation\n",
    "normal_set_RS1FPL = {}\n",
    "\n",
    "for i in range(len(new_repr)):\n",
    "    if rand_temp[i] == 0:\n",
    "        normal_set_RS1FPL[i] = new_repr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abnormal set creation\n",
    "abnormal_set_RS1FPL = {}\n",
    "for i in range(len(new_repr)):\n",
    "    if rand_temp[i] == 1:\n",
    "        abnormal_set_RS1FPL[i] = new_repr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_norms_N_RS1FPL = np.empty(0,)\n",
    "for (idel, sample) in normal_set_RS1FPL.items():\n",
    "    \n",
    "    # print(sample.shape)\n",
    "\n",
    "    l2_norms_N_RS1FPL = np.append(l2_norms_N_RS1FPL,get_matrix(sample))\n",
    "\n",
    "\n",
    "mu_GMM_RS1FPL, var_GMM_RS1FPL = estimate_gauss(np.array(l2_norms_N_RS1FPL))\n",
    "mu_GMM_RS1FPL, var_GMM_RS1FPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_RS1FPL = multivariate_normal(mu_GMM_RS1FPL, var_GMM_RS1FPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_RS1FPL = {} \n",
    "length = 0.2 \n",
    "\n",
    "for (idel, sample) in abnormal_set.items(): \n",
    "\n",
    "    # feature extraction \n",
    "    # sample_matrix = np.sum(np.square(sample), axis=1)  # for just l2\n",
    "    sample_matrix = get_matrix(sample)\n",
    "    \n",
    "    # get p values\n",
    "    probs = p_RS1FPL.pdf(sample_matrix)\n",
    "    temp_list = []\n",
    "    temp_list += [0.0] * len(probs)\n",
    "    \n",
    "    window_size = int(len(probs) * length)  # fixed\n",
    "    temp = []\n",
    "    for idx in range(0, len(probs) - window_size + 1):\n",
    "        arr = 0\n",
    "        for i in range(idx, idx + window_size - 1):\n",
    "            arr += abs(probs[i+1] - probs[i])\n",
    "        temp.append(arr)\n",
    "\n",
    "    for i in range(temp.index(max(temp)), temp.index(max(temp)) + window_size):\n",
    "        temp_list[i] = 1.0\n",
    "\n",
    "    ground_truth_RS1FPL[idel] = temp_list\n",
    "\n",
    "len(ground_truth_RS1FPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_gt_RS1FPL = []\n",
    "abnormal_gt_RS1FPL = []\n",
    "for i in range(len(new_repr)):\n",
    "    if i in normal_set_RS1FPL.keys():\n",
    "        final_gt_RS1FPL += [0.0] * new_repr[i].shape[0]\n",
    "    else:\n",
    "        final_gt_RS1FPL += ground_truth_RS1FPL[i]\n",
    "        abnormal_gt_RS1FPL+= ground_truth_RS1FPL[i]\n",
    "\n",
    "len(final_gt_RS1FPL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('unsupervised_PL/'+'UCF_labels_RS1FPL.npy', final_gt_RS1FPL) #UCF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Video-level labels experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_test = np.load(\"/home/anas.al-lahham/AnomalyDetection/RTFM/10_crop_features/Concat_test_10.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_crop_features = get_matrix(train_data[:580699])\n",
    "mu, var = estimate_gauss(n_train_crop_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = multivariate_normal(mu, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_list = '/home/anas.al-lahham/AD_Unsupervised/list/ucf-i3d-test.list'\n",
    "videos_list = list(open(videos_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "tlist = []\n",
    "for filename in videos_list:\n",
    "    filename = filename.strip('\\n')\n",
    "    sample = np.load(filename)\n",
    "\n",
    "    length = len(sample)\n",
    "    tlist.append((cnt, cnt + length))\n",
    "    cnt += length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_repr_test = []\n",
    "for i, (fromid, toid) in enumerate(tlist):\n",
    "    new_repr.append(con_test[fromid:toid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = [] \n",
    "length = 0.2 \n",
    "for filename in videos_list: \n",
    "    filename = filename.strip('\\n')\n",
    "    sample = np.load(filename)\n",
    "\n",
    "    # feature extraction \n",
    "    # sample_matrix = np.sum(np.square(sample), axis=1)  # for just l2\n",
    "    sample_matrix = get_matrix(sample)\n",
    "    \n",
    "    # get p values\n",
    "    # get p values\n",
    "    probs = p.pdf(sample_matrix)\n",
    "\n",
    "\n",
    "\n",
    "    temp_list = []\n",
    "    temp_list += [0.0] * len(probs)\n",
    "    \n",
    "\n",
    "    window_size = int(len(probs) * length)  # fixed\n",
    "    temp = []\n",
    "    for idx in range(0, len(probs) - window_size + 1):\n",
    "        arr = 0\n",
    "        for i in range(idx, idx + window_size - 1):\n",
    "            arr += abs(probs[i+1] - probs[i])\n",
    "        temp.append(arr)\n",
    "\n",
    "    for i in range(temp.index(max(temp)), temp.index(max(temp)) + window_size):\n",
    "        temp_list[i] = 1.0\n",
    "\n",
    "    ground_truth += temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_curve, precision_recall_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = np.load('list/gt-ucf-RTFM.npy')\n",
    "# print(gt.shape)\n",
    "pred = list(np.array(ground_truth))\n",
    "pred = np.repeat(np.array(pred), 16)\n",
    "# gt = gt[:len(pred)] \n",
    "\n",
    "fpr, tpr, threshold = roc_curve(list(gt), pred)\n",
    "\n",
    "\n",
    "rec_auc = auc(fpr, tpr)\n",
    "rec_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = np.concatenate((np.zeros(580699),np.ones(779951-580699)))\n",
    "ground_truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('unsupervised_PL/'+'UCF_labels_GTVSPL.npy', ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video-level pseudo-labels are directly attributed to the segments without refinement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_labels = np.load('Unsup_labels/UCF_unsup_labels_original_V2.npy')\n",
    "pseudo_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_list = list(open('list/ucf-i3d.list'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "nlist = []\n",
    "for video in all_list:\n",
    "    location = video.strip('\\n')\n",
    "    sample = np.load(location)\n",
    "\n",
    "    length = len(sample)\n",
    "    nlist.append((cnt, cnt + length))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "GTVSPL_ground_truth = []\n",
    "for video in all_list:\n",
    "    location = video.strip('\\n')\n",
    "    sample = np.load(location)\n",
    "\n",
    "    length = len(sample)\n",
    "    if np.sum(pseudo_labels[cnt:cnt+length]) == 0:\n",
    "        GTVSPL_ground_truth+= [0.0] * length\n",
    "\n",
    "    else:\n",
    "        GTVSPL_ground_truth+= [1.0] * length\n",
    "    cnt += length\n",
    "len(GTVSPL_ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('unsupervised_PL/'+'UCF_labels_GTVSPL.npy', GTVSPL_ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(GTVSPL_ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1 – p-value) is used as anomaly score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_labels = np.load('Unsup_labels/UCF_unsup_labels_original_V2.npy')\n",
    "pseudo_labels[:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "normal_set_C2PLnoAD = {}\n",
    "abnormal_set_C2PLnoAD = {}\n",
    "for i,video in enumerate(all_list):\n",
    "   location = video.strip('\\n')\n",
    "   sample = np.load(location)\n",
    "\n",
    "   length = len(sample)\n",
    "   if np.sum(pseudo_labels[cnt:cnt+length]) == 0:\n",
    "      normal_set_C2PLnoAD[i] = new_repr[i]\n",
    "   else:\n",
    "      abnormal_set_C2PLnoAD[i] = new_repr[i]\n",
    "      \n",
    "\n",
    "\n",
    "   cnt += length\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(normal_set_C2PLnoAD), len(abnormal_set_C2PLnoAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1344+265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_norms_N_C2PLnoAD = np.empty(0,)\n",
    "for (idel, sample) in normal_set_C2PLnoAD.items():\n",
    "    \n",
    "    # print(sample.shape)\n",
    "\n",
    "    l2_norms_N_C2PLnoAD = np.append(l2_norms_N_C2PLnoAD,get_matrix(sample))\n",
    "\n",
    "\n",
    "mu_GMM_C2PLnoAD , var_GMM_C2PLnoAD  = estimate_gauss(np.array(l2_norms_N_C2PLnoAD))\n",
    "mu_GMM_C2PLnoAD , var_GMM_C2PLnoAD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_C2PLnoAD  = multivariate_normal(mu_GMM_C2PLnoAD , var_GMM_C2PLnoAD )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_list = '/home/anas.al-lahham/AD_Unsupervised/list/ucf-i3d-test.list'\n",
    "videos_list = list(open(videos_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = [] \n",
    "p_value = []\n",
    "length = 0.2 \n",
    "for filename in videos_list: \n",
    "    filename = filename.strip('\\n')\n",
    "    sample = np.load(filename)\n",
    "\n",
    "    # feature extraction \n",
    "    # sample_matrix = np.sum(np.square(sample), axis=1)  # for just l2\n",
    "    sample_matrix = get_matrix(sample)\n",
    "    \n",
    "    # get p values\n",
    "    # get p values\n",
    "    probs = p_C2PLnoAD.pdf(sample_matrix)\n",
    "    \n",
    "    p_value = np.append(p_value, probs)\n",
    "\n",
    "    temp_list = []\n",
    "    temp_list += [0.0] * len(probs)\n",
    "    \n",
    "\n",
    "    window_size = int(len(probs) * length)  # fixed\n",
    "    temp = []\n",
    "    for idx in range(0, len(probs) - window_size + 1):\n",
    "        arr = 0\n",
    "        for i in range(idx, idx + window_size - 1):\n",
    "            arr += abs(probs[i+1] - probs[i])\n",
    "        temp.append(arr)\n",
    "\n",
    "    for i in range(temp.index(max(temp)), temp.index(max(temp)) + window_size):\n",
    "        temp_list[i] = 1.0\n",
    "\n",
    "    ground_truth += temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(10, 55, 5):\n",
    "\n",
    "\n",
    "    ground_truth_C2PLnoAD = {} \n",
    "    length = k/100\n",
    "\n",
    "    for (idel, sample) in abnormal_set_C2PLnoAD.items(): \n",
    "\n",
    "        # feature extraction \n",
    "        # sample_matrix = np.sum(np.square(sample), axis=1)  # for just l2\n",
    "        sample_matrix = get_matrix(sample)\n",
    "        \n",
    "        # get p values\n",
    "        probs = p_C2PLnoAD.pdf(sample_matrix)\n",
    "        temp_list = []\n",
    "        temp_list += [0.0] * len(probs)\n",
    "        \n",
    "        window_size = int(len(probs) * length)  # fixed\n",
    "        temp = []\n",
    "        for idx in range(0, len(probs) - window_size + 1):\n",
    "            arr = 0\n",
    "            for i in range(idx, idx + window_size - 1):\n",
    "                arr += abs(probs[i+1] - probs[i])\n",
    "            temp.append(arr)\n",
    "        # print(temp)\n",
    "        for i in range(temp.index(max(temp)), temp.index(max(temp)) + window_size):\n",
    "            temp_list[i] = 1.0\n",
    "\n",
    "        ground_truth_C2PLnoAD[idel] = temp_list\n",
    "\n",
    "    \n",
    "\n",
    "    final_gt_C2PLnoAD = []\n",
    "    abnormal_gt_C2PLnoAD = []\n",
    "    for i in range(len(new_repr)):\n",
    "        if i in normal_set_C2PLnoAD.keys():\n",
    "            final_gt_C2PLnoAD += [0.0] * new_repr[i].shape[0]\n",
    "        else:\n",
    "            final_gt_C2PLnoAD += ground_truth_C2PLnoAD[i]\n",
    "            abnormal_gt_C2PLnoAD+= ground_truth_C2PLnoAD[i]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    np.save('unsupervised_PL/'+f'UCF_labels_best_w_{k}.npy', final_gt_C2PLnoAD) #UCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('unsupervised_PL/'+'UCF_labels_best_w_15.npy', final_gt_C2PLnoAD) #UCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = np.load('list/gt-ucf-RTFM.npy')\n",
    "# print(gt.shape)\n",
    "# pred = list(np.array(ground_truth))\n",
    "pred = np.repeat(np.array(p_value), 16)\n",
    "# gt = gt[:len(pred)] \n",
    "\n",
    "fpr, tpr, threshold = roc_curve(list(gt), pred)\n",
    "\n",
    "\n",
    "rec_auc = auc(fpr, tpr)\n",
    "rec_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = [] \n",
    "p_value = []\n",
    "length = 0.2 \n",
    "for filename in videos_list: \n",
    "    filename = filename.strip('\\n')\n",
    "    sample = np.load(filename)\n",
    "\n",
    "    # feature extraction \n",
    "    # sample_matrix = np.sum(np.square(sample), axis=1)  # for just l2\n",
    "    sample_matrix = get_matrix(sample)\n",
    "    \n",
    "    # get p values\n",
    "    # get p values\n",
    "    probs = p.pdf(sample_matrix)\n",
    "    \n",
    "    p_value = np.append(p_value, probs)\n",
    "\n",
    "    temp_list = []\n",
    "    temp_list += [0.0] * len(probs)\n",
    "    \n",
    "\n",
    "    window_size = int(len(probs) * length)  # fixed\n",
    "    temp = []\n",
    "    for idx in range(0, len(probs) - window_size + 1):\n",
    "        arr = 0\n",
    "        for i in range(idx, idx + window_size - 1):\n",
    "            arr += abs(probs[i+1] - probs[i])\n",
    "        temp.append(arr)\n",
    "\n",
    "    for i in range(temp.index(max(temp)), temp.index(max(temp)) + window_size):\n",
    "        temp_list[i] = 1.0\n",
    "\n",
    "    ground_truth += temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = [] \n",
    "\n",
    "length = 0.15 \n",
    "for filename in all_list: \n",
    "    filename = filename.strip('\\n')\n",
    "    sample = np.load(filename)\n",
    "\n",
    "    # feature extraction \n",
    "    # sample_matrix = np.sum(np.square(sample), axis=1)  # for just l2\n",
    "    sample_matrix = get_matrix(sample)\n",
    "    \n",
    "    # get p values\n",
    "    # get p values\n",
    "    probs = p.pdf(sample_matrix)\n",
    "    \n",
    "\n",
    "\n",
    "    temp_list = []\n",
    "    temp_list += [0.0] * len(probs)\n",
    "    \n",
    "\n",
    "    window_size = int(len(probs) * length)  # fixed\n",
    "    temp = []\n",
    "    for idx in range(0, len(probs) - window_size + 1):\n",
    "        arr = 0\n",
    "        for i in range(idx, idx + window_size - 1):\n",
    "            arr += abs(probs[i+1] - probs[i])\n",
    "        temp.append(arr)\n",
    "\n",
    "    for i in range(temp.index(max(temp)), temp.index(max(temp)) + window_size):\n",
    "        temp_list[i] = 1.0\n",
    "\n",
    "    ground_truth += temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('unsupervised_PL/'+'UCF_labels_OCC_w_15.npy', ground_truth) #UCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
